[{"title":"Git","url":"/Git/","content":"学习备注\n1、要清楚执行每个git命令后 提示信息表达的意思，不会的单词要记忆，写在这个文档里面\n\n版本控制系统什么是版本控制系统\n版本控制系统是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统\n\n为什么要使用版本控制\n软件开发中采用版本控制系统是个明智的选择\n有了它你就可以将某个文件回溯到之前的状态,甚至将整个项目都回退到过去某个时间点的状态\n就算你乱来一气把整个项目中的文件改的改删的删，你也照样可以轻松恢复到原先的样子\n你可以比较文件的变化细节,查出最后是谁修改了哪个地方,从而找出导致怪异问题出现的原因，又是谁在何时报告了某个功能缺陷等等\n但额外增加的工作量却微乎其微\n\n版本管理的演变\nVCS 出现前\n用目录拷贝区别不不同版本\n公共文件容易易被覆盖\n成员沟通成本很高，代码集成效率低下\n\n\n集中式 VCS\n有集中的版本管理服务器\n具备文件版本管理和分支管理能力\n集成效率有明显地提高\n客户端必须时刻和服务器相连\n\n\n分布式 VCS\n服务端和客户端都有完整的版本库\n脱离服务端，客户端照样可以管理理版本\n查看历史和版本比较等多数操作，都不不需要访问服务器器，比集中式 VCS 更更能提⾼高版本管理理效率\n\n\n\n版本控制系统的分类集中化的版本控制系统\n\n\n集中化的版本控制系统诸如CVS, SVN 以及Perforce 等，都有一个单一的集中管理的服务器,保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器,取出最新的文件或者提交更新。多年以来,这已成为版本控制系统的标准做法,这种做法带来了许多好处,现在,每个人都可以在一定程度上看到项目中的其他人正在做些什么。而管理员也可以轻松掌控每个开发者的权限，并且管理一个集中化的版本控制系统;要远比在各个客户端上维护本地数据库来得轻松容易。\n事分两面，有好有坏。这么做最显而易见的缺点是中央服务器的单点故障。如果服务器宕机一小时，那么在这一小时内， 谁都无法提交更新，也就无法协同工作\n\n分布式的版本控制系统\n\n\n由于上面集中化版本控制系统的那些缺点，于是分布式版本控制系统面世了\n在这类系统中，像Git, BitKeeper 等,客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来\n许多这类系统都可以指定和若干不同的远端代码仓库进行交互。这样，你就可以在同一个项目中分别和不同工作小组的人相互协作\n\n\n\n\n分布式的版本控制系统在管理项目时存放的不是项目版本与版本之间的差异.它存的是索引(所需磁盘空间很少所以每个客户端都可以放下整个项目的历史记录)\n\n\n\n版本控制系统的存储方式\n世界上的版本控制总共有两种存储方式，一种是存储差异，另一种是存储快照\n存储差异：存储base文件，以后每次存储base文件的更改，SVN就是这种方式\n存储快照：每次更改都存储一个新文件，Git是这种方式\n\nGit 基础概念\nGit是一个免费的、开源的分布式版本控制系统，可以快速高效地管理从小型到大型的项目\n\nGit 简史\nLinux 内核开源项目有着为数众多的参与者。 绝大多数的 Linux 内核维护工作都花在了提交补丁和保存归档的繁琐事务上（1991－2002年间）。 到 2002 年，整个项目组开始启用一个专有的分布式版本控制系统 BitKeeper 来管理和维护代码。\n\n到了 2005 年，开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 这就迫使 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统。 他们对新的系统制订了若干目标\n\n\nGit 的使命 &#x2F; 目标Git在设计之初就是为了搞定linux内核这种巨无霸而设计的，所以制定了自己的使命\n\n速度\n简单的设计\n对非线性开发模式的强力支持（允许成千上万个并行开发的分支）\n完全分布式\n有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量）\n\nGit 的优点 &#x2F; 特点\n快、非凡的性能\n本地仓库\n轻量级分支\n分布式\n各种工作流\n最优的存储能力\n开源的\n很容易易做备份\n支持离线操作\n很容易易定制工作流程\n\nGit 的结构\n\nGit 的交互方式代码托管中心是干嘛的\n我们已经有了本地库，本地库可以帮我们进行版本控制，为什么还需要代码托管中心呢？它的任务是帮我们维护远程库\n\n本地库和远程库的交互方式团队内部协作\n\n跨团队协作\n\n托管中心种类\n局域网环境下：可以搭建 GitLab服务器作为代码托管中心，GitLab可以自己去搭建\n外网环境下：可以由GitHub或者Gitee作为代码托管中心，GitHub或者Gitee是现成的托管中心，不用自己去搭建\n\nGit 的下载安装 &#x2F; 基本设置\n下载安装略（官网下载，一般情况傻瓜式安装即可）\n查看git安装版本（是否安装成功）\n\ngit --version\n\n基本设置\n配置user.name和user.email\n\ngit config --global  user.name &#x27;sonzonzy&#x27;git config --global  user.email &#x27;sonzonzy@gmail.com&#x27;\n\nconfig 的三个作用域\n缺省等同于 local\n优先级：local &gt; global &gt; system\n\n# local只对当前仓库有效git config --local# global 对当前登录用户所有仓库有效git config --global# system 对系统的所有用户有效git config --system\n\n显示 config 的配置git config --list --localgit config --list --globalgit config --list --system\n\n信息设置与清除\n设置\t缺省等同于 local\n\ngit config --localgit config --globalgit config --system\n\n\n清除\t–unset\n\ngit config --unset --local user.namegit config --unset --global user.namegit config --unset --system user.name\n\nGit 常用命令 &amp; 操作init &#x2F; 初始化本地仓库# 在git终端进入到本地的文件夹 （例如 $ cd D:\\dev\\git_ws\\git_demo） 执行如下命令#初始化本地仓库git init\n\nadd &#x2F; 添加到暂存区git add .\n\ncommit &#x2F; 提交到本地仓库# 把暂存区的 文件提交到本地仓库。-m&quot;message&quot; 后的双引号 填写该次提交的说明信息git commit -m&quot;add test1.txt&quot;\n\n\n注意事项\n\n不放在本地仓库中的文件，git是不进行管理\n\n即使放在本地仓库的文件，git也不管理，必须通过add,commit命令操作才可以将内容提交到本地库\n\n\n\n\nstatus &#x2F; 查看工作区和暂存区的状态git status\n\nmv &#x2F; 重命名暂存区的文件\n方式一\n\nmv readme readme.mdgit rm readmegit add readme.mdgit commit -m&quot;rename file&quot;\n\n\n方式二\n\ngit mv readme readme.mdgit commit -m&#x27;file name&#x27;\n\nlog &#x2F; 查看提交日志# 可以让我们查看提交的，显示从最近到最远的日志git log -n[number] --graph --online --all/[branch_name]# -n 指定查看条数# --graph 图形化查看# --online 简单显示# --all 显示所有分支，不加则显示当前分支# branch_name 指定分支git log --pretty=onelinegit reflog# 多了信息：HEAD@&#123;数字&#125; 这个数字的含义：指针回到当前这个历史版本需要走多少步\n\n# 在浏览器打开git log 的帮助文档git help --web log\n\ngitk &#x2F; git 的gui界面# 打开git的gui界面gitk\n\nrest &#x2F; 前进或者后退历史版本hard 参数# 本地库的指针移动的同时，重置暂存区，重置工作区git reset --hard [索引]\n\nmixed参数# 本地库的指针移动的同时，重置暂存区，但是工作区不动git reset --mixed [索引]\n\nsoft参数# 本地库的指针移动的时候，暂存区，工作区都不动git reset --soft [索引]\n\ndiff# 将工作区中的文件和暂存区中文件进行比较 git diff [文件名]  # 比较工作区中和暂存区中 所有文件的差异git diff# 比较暂存区和工作区中内容git diff [历史版本] [文件名] \n\n分支","categories":["git"],"tags":["git"]},{"title":"linux实战技能","url":"/linux%E5%AE%9E%E6%88%98%E6%8A%80%E8%83%BD/","content":"学习备注\nlinux下的打包 压缩还需深入理解 和操作\n\nlinux 基础介绍\nlinux有两种含义\n\n一种是linus编写的开源操作系统内核\n另一种是广义的操作系统\n\n\n内核版本（分为三个部分）\n\n主版本号、次版本号、末版本号\n次版本号是奇数为开发版本，偶数为稳定版\n\n\n\nlinux 常见目录介绍\n&#x2F; 根目录\n&#x2F;root root用户家目录\n&#x2F;home&#x2F;username 普通用户的家目录\n&#x2F;etc 配置文件目录\n&#x2F;bin 命令目录\n&#x2F;sbin 管理命令目录\n&#x2F;usr&#x2F;bin &#x2F;usr&#x2F;sbin 系统预装的其它命令\n\nlinux 关机 &#x2F; 重启 命令# 关机init 0# 延时关机 19:30关机shutdown -h 19:30# 延时30分钟关机shutdown -h +30 # 重启reboot\n\n系统操作帮助命令man# man是manual的缩写# 演示man ls\n\nhelp\nshell 自带的命令称为内部命令，其它的是外部命令\n\n# 内部命令使用 help 帮助help cd# 外部命令使用 help 帮助ls --help\n\ninfo\ninfo 帮助比 help 更详细，作为 help 的补充\n\ninfo ls\n\n文件 - 增删改查\nlinux 操作系统中，一切皆文件\n\n# 创建非空目录 mkdir [参数]# -p 递归创建目录mkdir -p [参数]\n\n# 删除非空目录rm [参数]# 递归删除目录（包括目录下的所有文件）rm -r [参数]# 不提示，无需确认，递归删除目录rm -rf [参数]\n\n# 仅仅复制文件cp [] []# 复制文件 or 目录cp -r [] []# -v 查看复制提示、过程  -p 复制的文件保留原文件的时间 -a 保留权限、保留属主cp -vpa [] []\n\n# 移动文件mv [参数] [源文件] [目标文件/目录]# 重命名mv [] []\n\n# 查看当前目录下的文件ls [选项...] [参数...]# -l 长格式显示文件# -a 显示隐藏文件# -r 逆序显示# -t 按照时间顺序显示# -R 递归显示ll\n\n通配符\n定义：shell 内建的符号\n用途：操作多个相似（有规律）的文件\n常用通配符\n* 匹配任意字符串\n? 匹配一个字符串\n[xyz] 匹配xyz任意一个字符\n[a-z] 匹配一个范围\n[!xyz] 或 [^xyz] 不匹配\n\n\n\n文本touch []\n\n# 文本内容显示到终端cat []# 查看文件开头 -number  表示查看文件开头的number行 。不加默认查看10行head -5 []# 查看文件结尾 -number 表示查看文件结尾哦的number行 。不加默认查看10行  -f文件内容更新后，显示同步更新tail -20 -f []# 统计文件内容信息wc []# 查看文件行数wc -l []more [filename]less [filename]\n\n打包 &#x2F; 压缩","tags":["linux"]},{"title":"kingbase","url":"/kingbase/","content":"Kingbase 安装与启停安装前准备工作\n服务器安装jdk1.8+版本并配置环境变量\n\n创建kingbase用户组与用户。创建目录，并设置目录属组、属组、权限\n\n上传kingbase安装包和kingbase的license.dat 到服务器（安装包和license可以到官网下载） \n\n\n# 为了利于数据库的日常运维、持续使用、存储扩容等，我们在安装前需做好选项、存储目录规划# 使用root用户登录进服务器# /install 安装软件上传目录  /kingbase/V8  数据库安装目录  /backup 备份目录  /data 数据存储目录  /archive 归档目录mkdir -p /install /KingbaseES/V8 /backup /data /archive# 上传 安装包、license.dat 到 /install 目录  # optimize_system_conf_kcp.sh 优化操作系统的脚本   optimize_database_conf.sh 优化数据库的脚本 [root@node1 install]# ll /install总用量 852348-rw-r--r--. 1 root root 872781824 5月  11 03:27 KingbaseES_V008R006C005B0023_Lin                                      64_single_install.iso-rw-r--r--. 1 root root      3351 5月  11 03:27 license_12350_0.dat-rw-r--r--. 1 root root      6504 5月  11 03:27 optimize_database_conf.sh-rw-r--r--. 1 root root      8023 5月  11 03:27 optimize_system_conf_kcp.sh# 执行 优化操作系统的脚本。主要帮我们 创建了kingbase 用户组和用户（用户密码：kingbase）。具体详情可以查看脚本内容bash /install/optimize_system_conf_kcp.sh[root@node1 install]# id kingbaseuid=1001(kingbase) gid=1001(kingbase) 组=1001(kingbase)# 修改目录属组、属主、权限chown -R kingbase:kingbase /install /KingbaseES /backup /archive /datachmod -R 775 /install /KingbaseES /backup /archivechmod -R 700 /data\n\n \n\nKingbase 安装# 我们使用的是 KingbaseES_V008R006C005B0023_Lin64_single_install.iso 文件，所以先使用root用户登录并挂载[root@node1 install]# mount -o loop /install/KingbaseES_V008R006C005B0023_Lin64_single_install.iso  /mnt/[root@node1 install]# ll /mnt/总用量 6dr-xr-xr-x. 2 root root 2048 11月  5 2021 setup-r-xr-xr-x. 1 root root 3820 11月  5 2021 setup.sh\n\n# # 使用kingbase 用户登录服务器 ，进入/mnt 下执行 setup.sh 则开始安装 （[kingbase@node1 mnt]$ cd /mnt[kingbase@node1 mnt]$ bash setup.sh# 也可以使用命令行安装./setup.sh -i console\n\n# 安装完成后 使用root用户登录进服务器，把数据库服务注册成系统服务。并启动数据库[root@node1 ~]# /KingbaseES/V8/Scripts/root.sh# 把kingbase注册成系统服务后（root用户执行 /KingbaseES/V8/Scripts/root.sh 后）。kingbase已经启动了，但此时 为什么不可以使用 systemctl  这种方式启停 kingbase？# 必须 使用sys_ctl 数据库先停止. 然后再使用systemctl 启动数据. 才能成功启动, 因为systemctl 需要获取进程状态信息.\n\n\n运行 数据库优化文件\n\nbash /install/optimize_database_conf.sh\n\n\n\nKingbase 相关环境变量配置# 使用kingbase用户登录。配置ksql环境变量[root@sonronzy ~]# su - kingbase[kingbase@sonronzy ~]$ cd ~[kingbase@sonronzy ~]$ vi .bashrcexport PATH=/KingbaseES/V8/Server/bin:$PATH[kingbase@sonronzy ~]$ source .bashrc\n\n# 使用kingbase用户登录 ，使用sys_ctl 专用命令管理金仓数据库# 配置sys_ctl 环境变量[kingbase@sonronzy ~]$ cd ~[kingbase@sonronzy ~]$ vim .bashrcexport PATHexport KINGBASE_DATA=/dataexport PATH=/KingbaseES/V8/Server/bin:$PATH[kingbase@sonronzy ~]$ source .bashrc\n\n\n\nKingbase 启停# kingbase 是进程，kingbase8d 是服务# 注意没有修改linux参数的时候 systemctl 和 service 方式启停数据库 不要混用service kingbase8d start/stop/restart/statusservice kingbase8 start/stop/restart/statussystemctl start kingbase8d/etc/init.d/kingbase8d start# kingbase用户 ，使用sys_ctl 专用命令管理金仓数据库# 首先要配置 环境变量sys_ctl start/stop/restart/status\n\n# 有任何用户连接到数据库里来，都无法关闭数据库，必须等所有用户提交完数据断开连接后 才可关闭数据库。这个可能会关闭很长时间sys_ctl stop -m smart# 默认方式 关闭数据库。最好选用这个。 已经提交的用户踢开连接，未提交的用户 回滚，然后关闭数据库（一致状态，安全关闭方式）sys_ctl stop -m fast | sys_ctl stop# 断电式关闭数据库 (不推荐，可能会导致数据不一致，数据库无法启动)sys_ctl -m immediate\n\n\n\nKingbase 卸载# 使用root用户登录，进入到数据库的安装目录下的 Scripts 目录下，执行 rootuninstall.sh 卸载kingbase数据库cd /KingbaseES/V8/Scripts/KingbaseES/V8/Scripts/rootuninstall.sh# 最后确认已删除的kingbase8d 服务\n\n\n\n实践环境中常见的问题\n\n\n\n* 注意事项Kingbase数据库大小写敏感说明及转换Kingbase数据库大小写敏感说明及转换\n\n\nKingbase 客户端Kingbase 对象管理器\n我们安装kingbase的时候，如果选择完全安装，则会帮我们安装上 数据库对象管理工具\n使用Kingbase 对象管理器连接数据库 操作如下图\n\n\n\n模式\n业务软件所使用的对象的集合。包括：表、视图、序列、索引、函数、存储过程等……\n非模式对象：表空间\n\n\n\n其它客户端\n当我们不想在本机安装kingbase数据库时，可以选择第三方数据库客户端连接kingbase数据库。可以使用的相关客户端有：DBeaver、DataGrip 2020.1 x64、Dbvisualizer\n\n\n\nDBeaver\n官网 下载 DBeaver\n使用DBeaver 连接Kingbase 数据库 操作如下图\n\n\n\n\n\n \n\n\n\nksql 命令行工具\nKsql是Kingbase的交互式终端\n支持上下键翻页，tab键补全\n\n\n\nksql登录 、执行sql语句、sql脚本ksql -Usystem -h localhost -p54321 -W TESTksql -Usystem -W xjnxdb -lksql -Usystem -W xjnxdb -c  &quot;select * from xjnxdb.pa_user&quot;ksql -Usystem -W xjnxdb -f /home/kingbase/1.sql\n\n\n\nksql终端常用快捷键# 查看所有快捷键\\?# help\\h create# 查看当前有哪些数据库\\l# 查看表结构\\d xjxndb.pa_user\\c 切换数据库23:17:59 (system@[local]:54321)TEST=# \\c template1口令：您现在已经连接到数据库 &quot;template1&quot;,用户 &quot;system&quot;.23:18:09 (system@[local]:54321)template1=## 退出ksql终端\\q\n\n\n\n自定义sql提示符# 定制sql提示符，便于我们了解 目前在哪台终端、哪个用户、哪个数据库下操作# 使用kingbase用户登录[kingbase@sonronzy ~]$ vim ~/.ksqlrc[kingbase@sonronzy ~]$[kingbase@sonronzy ~]$ cat ~/.ksqlrc\\set PROMPT1 &#x27;%`date +%H:%M:%S` (%n@%M:%&gt;)%/%R%#%x &#x27;\\set PROMPT2 &#x27;%M %n@%/%R%# &#x27;[kingbase@sonronzy ~]$[kingbase@sonronzy ~]$ source ~/.ksqlrc[kingbase@sonronzy ~]$[kingbase@sonronzy ~]$ ksql -Usystem -W TEST口令：ksql (V8.0)输入 &quot;help&quot; 来获取帮助信息.23:13:03 (system@[local]:54321)TEST=#\n\n\\set PROMPT1 &#x27;%`date +%H:%M:%S` (%n@%M:%&gt;)%/%R%#%x &#x27;\\set PROMPT2 &#x27;%M %n@%/%R%# &#x27;\n\n解析：◆ %M  \t指数据库服务器的主机名 - 如果连接是通过 Unix 域套接字，则为“[local]”◆ %m  \t也表示数据库主机名，会截断第一个 . 后的内容◆ %&gt;\t\t数据库端口号◆ %n\t\t是指会话用户名◆ %&#x2F;\t\t当前数据库名◆ %#\t\t如果是超级用户显示为 #，否则显示为 &gt;◆ %R\t\t是指您处于单行模式（^）还是断开连接（！ ） ，但通常为&#x3D;◆ %x\t\t指的是事务状态 - 通常为空白，除非在事务块（*）\n\n\n常用sqlshow database_mode;show shared_buffers;select get_license_validdays();\n\n\n\n\n\ncopy 与 \\copy\ncopy 命令属于 SQL 命令， \\copy 命令属于元命令\ncopy 命令进行数据导出、导入时，需要具有 superuser 的权限；导出至 stdout 时，仅需模式、对象的相关权限即可；\\copy 命令进行数据导出、导入时，无需 superuser 权限\ncopy 命令只能在源数据库服务器上进行数据导出、导入；\\copy 命令还可以通过远程服务器连接至源数据库服务器，将数据导出至远程服务器、或将远程服务器的数据导入源数据库中\n大数据量的数据进行导出、导入时，copy 比\\copy 的性能高\n如果进行小数据量导出、导入，建议通过\\copy 操作便利；大数据量操作时，建议在源数据库中使用 copy 效率更高\n\n\n\nKingbase 数据迁移第一步：基础数据结构及数据迁移\n准备工作\n根据需要创建用户、表空间、模式等对象\n\n\n使用【数据库迁移工具】完成基础数据迁移工作\n\n\n\n第二步：应用接口及框架迁移springboot 数据源配置#环境业务自身配置开始#默认数据源default，不能修改spring.datasource.dynamic.primary = default#默认数据源，名称 default#spring.datasource.dynamic.datasource.default.driver-class-name=com.mysql.jdbc.Driver#spring.datasource.dynamic.datasource.default.url=jdbc:mysql://localhost:3306/xjnxdb?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=UTC&amp;useSSL=false#spring.datasource.dynamic.datasource.default.username=root#spring.datasource.dynamic.datasource.default.password=root#kingbase 数据源配置spring.datasource.dynamic.datasource.default.driver-class-name=com.kingbase8.Driverspring.datasource.dynamic.datasource.default.url=jdbc:kingbase8://10.114.12.66:54321/xjnxdbspring.datasource.dynamic.datasource.default.username=xjnxdbspring.datasource.dynamic.datasource.default.password=xjnxdb\n\n\n\nmaven 配置Kingbase 驱动在maven repository中查找kingbase的驱动依赖配置，加入到我们的pom文件\n&lt;!-- https://mvnrepository.com/artifact/kingbase/kingbase8 --&gt;&lt;dependency&gt;    &lt;groupId&gt;kingbase&lt;/groupId&gt;    &lt;artifactId&gt;kingbase8&lt;/artifactId&gt;    &lt;version&gt;8&lt;/version&gt;&lt;/dependency&gt;\n\n\n注意：我们会发现Kingbase8驱动依赖根本下载不下来。此时：我们可以把驱动下载到本地，再使用maven命令install到maven本地仓库即可\n\nkingbase8-8.jar\nmvn install:install-file -DgroupId=kingbase -DartifactId=kingbase8 -Dversion=8 -Dfile=D:\\bak\\kingbase8-8.jar -Dpackaging=jar -DgeneratePom=true\n\n\n该语句中参数：\nDgroupId ：组id 【对应pom中的groupId】DartifactId：项目id 【对应pom中的artifactId】Dversion：版本号 【对应pom中的version】Dfile：jar包的绝对路径Dpackaging：是什么包DgeneratePom：是否生成pom\n\n\n最后在pom中直接写入 dependency 就可以了，刷新即可使用\n\n&lt;!-- https://mvnrepository.com/artifact/kingbase/kingbase8 --&gt;&lt;dependency&gt;    &lt;groupId&gt;kingbase&lt;/groupId&gt;    &lt;artifactId&gt;kingbase8&lt;/artifactId&gt;    &lt;version&gt;8&lt;/version&gt;&lt;/dependency&gt;\n\n\n\n第三步：应用功能测试（SQL兼容情况）date_format 函数支持@Mapper@TableInfo(name = &quot;wf_sequence&quot;, primaryKeys = &#123;&quot;seqNo&quot;&#125;)public interface WfSequenceMapper &#123;\t@Update(&quot;update wf_sequence set seqval = seqval+1 where seqno=#&#123;seqNo&#125;&quot;)\tint incBySeqNo(@Param(&quot;seqNo&quot;) String seqNo);\t@Select(&quot;select * from wf_sequence where seqno=#&#123;seqNo&#125;&quot;)\tWfSequenceDO getBySeqNo(@Param(&quot;seqNo&quot;) String seqNo);\t@Insert(&quot;insert into wf_sequence (seqno,seqval,seqdesc)values(#&#123;seqNo&#125;,#&#123;seqVal&#125;,#&#123;seqDesc&#125;)&quot;)\tint insert(WfSequenceDO seq);\t@Select(&quot;SELECT concat(DATE_FORMAT(sysdate(),&#x27;%Y%m%d&#x27;),right(lpad(seqval,15,0),8)) as seqDesc FROM wf_sequence where seqno=#&#123;seqNo&#125;&quot;)\tWfSequenceDO getTxnBySeqNo(@Param(&quot;seqNo&quot;) String seqNo);&#125;\n\n00:28:12 (system@[local]:54321)TEST=# select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);错误:  函数 date_format(unknown, unknown) 不存在第1行select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);            ^提示:  没有匹配指定名称和参数类型的函数. 您也许需要增加明确的类型转换.00:28:15 (system@[local]:54321)TEST=#\n\n\n参考 《[应用开发及迁移][参考手册]KingbaseES扩展插件参考手册.pdf》\n\n\n\nkdb_date_function\n\nkdb_date_function 是一个兼容 mysql 数据库 date 相关函数的扩展。使用时需要 create extension kdb_date_function，不需要时 drop extension kdb_date_function 即可。\n\n00:41:28 (system@[local]:54321)TEST=# select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);错误:  函数 date_format(unknown, unknown) 不存在第1行select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;);            ^提示:  没有匹配指定名称和参数类型的函数. 您也许需要增加明确的类型转换.00:41:29 (system@[local]:54321)TEST=#00:41:30 (system@[local]:54321)TEST=#00:41:30 (system@[local]:54321)TEST=#00:41:30 (system@[local]:54321)TEST=# create extension kdb_date_function;CREATE EXTENSION00:44:42 (system@[local]:54321)TEST=# select date_format(&#x27;2022-05-15&#x27;,&#x27;yyyy-mm-dd&#x27;); date_format------------- 2022-05-15(1 行记录)00:44:46 (system@[local]:54321)TEST=#\n\n\n\n数据库迁移评估系统\n具体详情参考官方文档\n\n","categories":["database","kingbase"],"tags":["database","kingbase"]},{"title":"《Java 并发编程实战》study notes","url":"/%E3%80%8AJava-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"前言\n近期在学习极客时间的专栏《Java 并发编程实战》，对专栏的核心知识做了学习笔记，便于复习\n\n开篇词 | 你为什么需要学习并发编程？\n近几年，并发编程已经慢慢成为一项必备技能\n\n\n\n学习攻略 | 如何才能学好并发编程？跳出来，看全景\n首要之事就是你建立起一张全景图\n并发编程领域可以抽象成三个核心问题：分工、同步和互斥\n\n\n\n分工\nJava SDK 并发包里的 Executor、Fork&#x2F;Join、Future 本质上都是一种分工方法\n并发编程领域总结出设计模式：生产者 - 消费者、Thread-Per-Message、Worker Thread 模式等都是用来指导你如何分工的\n\n\n学习这部分内容，最佳的方式就是和现实世界做对比。例如生产者 - 消费者模式，可以类比一下餐馆里的大厨和服务员，大厨就是生产者，负责做菜，做完放到出菜口，而服务员就是消费者，把做好的菜给你端过来。不过，我们经常会发现，出菜口有时候一下子出了好几个菜，服务员是可以把这一批菜同时端给你的。其实这就是生产者 - 消费者模式的一个优点，生产者一个一个地生产数据，而消费者可以批处理，这样就提高了性能\n\n\n\n同步\n在并发编程领域里的同步，主要指的就是线程间的协作。一个线程执行完了一个任务，如何通知执行后续任务的线程开工\n协作一般是和分工相关的。Java SDK 并发包里的 Executor、Fork&#x2F;Join、Future 本质上都是分工方法，但同时也能解决线程协作的问题\n\n\n例如，用 Future 可以发起一个异步调用，当主线程通过 get() 方法取结果时，主线程就会等待，当异步执行的结果返回时，get() 方法就自动返回了。主线程和异步线程之间的协作，Future 工具类已经帮我们解决了\n\n\n线程协作问题，基本上都可以描述为：当某个条件不满足时，线程需要等待，当某个条件满足时，线程需要被唤醒执行\n\n\n例如，在生产者 - 消费者模型里：当队列满时，生产者线程等待，当队列不满时，生产者线程需要被唤醒执行；当队列空时，消费者线程等待，当队列不空时，消费者线程需要被唤醒执行\n\n\n在 Java 并发编程领域，解决协作问题的核心技术是管程，管程是解决并发问题的万能钥匙。（解决线程协作问题、互斥问题）\n\n\n这部分内容的学习，关键是理解管程模型，学好它就可以解决所有问题。其次是了解 Java SDK 并发包提供的几个线程协作的工具类的应用场景，用好它们可以妥妥地提高你的工作效率\n\n\n\n互斥\n分工、同步主要强调的是性能，但并发程序里还有一部分是关于正确性的，用专业术语叫“线程安全”。并发程序里，当多个线程同时访问同一个共享变量的时候，结果是不确定的。不确定，则意味着可能正确，也可能错误，事先是不知道的。而导致不确定的主要源头是可见性问题、有序性问题和原子性问题，为了解决这三个问题，Java 语言引入了内存模型，内存模型提供了一系列的规则，利用这些规则，我们可以避免可见性问题、有序性问题，但是还不足以完全解决线程安全问题。解决线程安全问题的核心方案还是互斥。\n\n\n互斥，指的是同一时刻，只允许一个线程访问共享变量\n\n实现互斥的核心技术就是锁\n\n\n\n锁解决了安全性问题，但同时也带来了性能问题，那如何保证安全性的同时又尽量提高性能呢？可以分场景优化，Java SDK 里提供的 ReadWriteLock、StampedLock 就可以优化读多写少场景下锁的性能。还可以使用无锁的数据结构，例如 Java SDK 里提供的原子类都是基于无锁技术实现的。\n除此之外，还有一些其他的方案，原理是不共享变量或者变量只允许读。这方面，Java 提供了 Thread Local 和 final 关键字，还有一种 Copy-on-write 的模式。\n使用锁除了要注意性能问题外，还需要注意死锁问题。\n\n\n这部分内容比较复杂，往往还是跨领域的，例如要理解可见性，就需要了解一些 CPU 和缓存的知识；要理解原子性，就需要理解一些操作系统的知识；很多无锁算法的实现往往也需要理解 CPU 缓存。这部分内容的学习，需要博览群书，在大脑里建立起 CPU、内存、I&#x2F;O 执行的模拟器。这样遇到问题就能得心应手了。\n\n\n\n\n钻进去，看本质\n光跳出来还不够，还需要下一步，就是在某个问题上钻进去，深入理解，找到本质\n工程上的解决方案，一定要有理论做基础\n\n\n探索它背后的理论是什么。分析这些概念和结论是怎么来的，以及它们是用来解决什么问题的\n\n\n\n总结\n要让自己的知识成体系，一定要挖掘 Java SDK 并发包背后的设计理念\n分工、同步和互斥的全景图，是我对并发问题的个人总结，不一定正确，但是可以帮助我快速建立解决并发问题的思路，梳理并发编程的知识，加深认识\n对于某个具体的技术，我建议你探索它背后的理论本质\n探求理论本质，既能加深对技术本身的理解，也能拓展知识深度和广度，这是个一举多得的方法\n\n\n\n第一部分：并发理论基础01 | 可见性、原子性和有序性问题：并发编程Bug的源头并发程序幕后的故事\n核心矛盾一直存在，就是这三者（CPU、内存、I&#x2F;O 设备）的速度差异\n为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系机构、操作系统、编译程序都做出了贡献，主要体现为：\n\n\n\nCPU 增加了缓存，以均衡与内存的速度差异；\n操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I&#x2F;O 设备的速度差异；\n编译程序优化指令执行次序，使得缓存能够得到更加合理地利用\n\n\n源头之一：缓存导致的可见性问题源头之二：线程切换带来的原子性问题源头之三：编译优化带来的有序性问题总结课后思考备注","categories":["java","concurrent"],"tags":["concurrent","java"]},{"title":"《MySQL 必知必会》study notes","url":"/%E3%80%8AMySQL-%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A%E3%80%8Bstudy-notes/","content":"前言\n近期学习了极客时间的专栏《MySQL 必知必会》，对专栏的核心知识做了学习笔记，便于复习\n\n\n\n课前准备 (2讲)开篇词-在实战中学习，是解锁MySQL技能的最佳方法\n熟练使用MySQL，对技术人来说变得越来越重要，是我们拿到心仪Offer的敲门砖\n最重要的绝对不是你的知识储备量，而是你解决实际问题的能力\n正确的学习方法，远比你投入的时间更重要。而实战，就是最高效的方法\n项目的实际需求–&gt;解决问题所需的知识点–&gt;用好这些知识的实战经验\n\n\n\n实践篇 (13讲)01-存储：一个完整的数据存储过程是怎样的？\n一个完整的数据存储过程总共有4步，分别是创建数据库、确认字段、创建数据表、插入数据\n\n\n\n\nMySQL数据库系统从大到小依次是数据库服务器、数据库、数据表、数据表的行与列\n数据库是MySQL里面最大的存储单元\n\n CREATE DATABASE `demo`  DEFAULT CHARACTER SET utf8mb4;(root@localhost) [demo]&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || dbt3_s1            || demo               || mysql              || performance_schema || sys                |+--------------------+6 rows in set (0.00 sec)\n\n\n“information_schema”是MySQL系统自带的数据库，主要保存MySQL数据库服务器的系统信息，比如数据库的名称、数据表的名称、字段名称、存取权限、数据文件所在的文件夹和系统使用的文件夹，等等。\n\n“performance_schema”是MySQL系统自带的数据库，可以用来监控MySQL的各类性能指标\n\n“sys”数据库是MySQL系统自带的数据库，主要作用是，以一种更容易被理解的方式展示MySQL数据库服务器的各类性能指标，帮助系统管理员和开发人员监控MySQL的技术性能\n\n“mysql”数据库保存了MySQL数据库服务器运行时需要的系统信息，比如数据文件夹、当前使用的字符集、约束检查信息，等等\n\n创建表的时候，最好指明数据库\n\n\nCREATE TABLE demo.test(   barcode text,  goodsname text,  price int); describe demo.test;\n\n如何设置主键\nMySQL中数据表的主键，是表中的一个字段或者几个字段的组合。它主要有3个特征\n\n必须唯一，不能重复；\n不能是空；\n必须可以唯一标识数据表中的记录\n\n\n如果数据表中所有的字段都有重复的可能。我们可以自己添加一个不会重复的字段来做主键\n\n\nALTER TABLE demo.test ADD COLUMN itemnumber int PRIMARY KEY AUTO_INCREMENT;\n\n02-字段：这么多字段类型，该怎么定义？整数类型\n\n\n最佳实践\n在评估用哪种整数类型的时候，你需要考虑存储空间和可靠性的平衡问题\n确保数据不会超过取值范围，再去考虑如何节省存储空间\n\n\n\n浮点数类型和定点数类型\nFLOAT表示单精度浮点数\nDOUBLE表示双精度浮点数\nREAL默认就是DOUBLE。如果你把SQL模式设定为启用“REAL_AS_FLOAT”，那么，MySQL就认为REAL是FLOAT\nSET sql_mode = &quot;REAL_AS_FLOAT&quot;;\n\n\nFLOAT占用字节数少，取值范围小；DOUBLE占用字节数多，取值范围也大\n\n\n\n\n为什么浮点数类型的无符号数取值范围，只相当于有符号数取值范围的一半，也就是只相当于有符号数取值范围大于等于零的部分呢？\n\n\n原因是，MySQL是按照这个格式存储浮点数的：符号（S）、尾数（M）和阶码（E）。因此，无论有没有符号，MySQL的浮点数都会存储表示符号的部分。因此，所谓的无符号数取值范围，其实就是有符号数取值范围大于等于零的部分。\n\n浮点数类型有个缺陷，就是不精准\n问题还是出在MySQL对浮点类型数据的存储方式上\n\n\nMySQL用4个字节存储FLOAT类型数据，用8个字节来存储DOUBLE类型数据。无论哪个，都是采用二进制的方式来进行存储的。比如9.625，用二进制来表达，就是1001.101，或者表达成1.001101×2^3。看到了吗？如果尾数不是0或5（比如9.624），你就无法用一个二进制数来精确表达。怎么办呢？就只好在取值允许的范围内进行近似（四舍五入）。\n为什么数据类型是DOUBLE的时候，我们得到的结果误差更小一些，而数据类型是FLOAT的时候，误差会更大一下。原因就是，DOUBLE有8位字节，精度更高\n\n定点数类型：DECIMAL\nDECIMAL的存储方式决定了它一定是精准的\n\n\n浮点数类型是把十进制数转换成二进制数存储，DECIMAL则不同，它是把十进制数的整数部分和小数部分拆开，分别转换成十六进制数，进行存储。这样，所有的数值，就都可以精准表达了，不会存在因为无法表达而损失精度的问题\n\n浮点数和定点数的特点&#x2F;最佳实践\n浮点类型取值范围大，但是不精准，适用于需要取值范围大，又可以容忍微小误差的科学计算场景（比如计算化学、分子建模、流体动力学等）；定点数类型取值范围相对小，但是精准，没有误差，适合于对精度要求极高的场景（比如涉及金额计算的场景）\n\n文本类型\nCHAR(M)：固定长度字符串。CHAR(M)类型必须预先定义字符串长度。如果太短，数据可能会超出范围；如果太长，又浪费存储空间。\n\nVARCHAR(M)： 可变长度字符串。VARCHAR(M)也需要预先知道字符串的最大长度，不过只要不超过这个最大长度，具体存储的时候，是按照实际字符串长度存储的。\n\nTEXT：字符串。系统自动按照实际长度存储，不需要预先定义长度。\n\nENUM： 枚举类型，取值必须是预先设定的一组字符串值范围之内的一个，必须要知道字符串所有可能的取值。\n\nSET：是一个字符串对象，取值必须是在预先设定的字符串值范围之内的0个或多个，也必须知道字符串所有可能的取值。\n\nTEXT类型也有4种，它们的区别就是最大长度不同。\n\nTINYTEXT：占用255字符。\n\nTEXT： 占用65535字符。\n\nMEDIUMTEXT：占用16777215字符。\n\nLONGTEXT： 占用4294967295字符（相当于4GB）\n\n\n\nTEXT也有一个问题：由于实际存储的长度不确定，MySQL不允许TEXT类型的字段做主键。遇到这种情况，你只能采用CHAR(M)，或者VARCHAR(M)\n\n最佳实践\n\n项目中，只要不是主键字段，就可以按照数据可能的最大长度，选择这几种TEXT类型中的的一种，作为存储字符串的数据类型\n\n\n\n日期与时间类型\n\n\n最佳实践\n\n\n在实际项目中，尽量用DATETIME类型。因为这个数据类型包括了完整的日期和时间信息，使用起来比较方便\n为了确保数据的完整性和系统的稳定性，优先考虑使用DATETIME类型。因为虽然DATETIME类型占用的存储空间最多，但是它表达的时间最为完整，取值范围也最大\n\n\n为什么时间类型TIME的取值范围不是-23:59:59～23:59:59呢\n\n\n原因是MySQL设计的TIME类型，不光表示一天之内的时间，而且可以用来表示一个时间间隔，这个时间间隔可以超过24小时。\n\n最佳实践\n在定义数据类型时，如果确定是整数，就用INT；如果是小数，一定用定点数类型DECIMAL；如果是字符串，只要不是主键，就用TEXT；如果是日期与时间，就用DATETIME。\n\n03 | 表：怎么创建和修改数据表？\n\nSQL汇总-- 创建数据库CREATE DATABASE demo；-- 删除数据库DROP DATABASE demo；-- 查看数据库SHOW DATABASES;-- 创建数据表：CREATE TABLE demo.test(    barcode text,  goodsname text,  price int); -- 查看表结构DESCRIBE demo.test;-- 查看所有表-- DESCRIBE TABLES;-- 添加主键ALTER TABLE demo.testADD COLUMN itemnumber int PRIMARY KEY AUTO_INCREMENT;-- 向表中添加数据INSERT INTO demo.test(barcode,goodsname,price)VALUES (&#x27;0001&#x27;,&#x27;本&#x27;,3);-- 修改字段类型语句ALTER TABLE demo.goodsmasterMODIFY COLUMN price DOUBLE;-- 计算字段合计函数：SELECT SUM(price)FROM demo.goodsmaster;\n\n\n\n\n\n备注","categories":["database","mysql"],"tags":["database","mysql"]},{"title":"《Web 协议详解与抓包实战》study notes","url":"/%E3%80%8AWeb-%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3%E4%B8%8E%E6%8A%93%E5%8C%85%E5%AE%9E%E6%88%98%E3%80%8Bstudy-notes/","content":"HTTP&#x2F;1.1协议浏览器发起 HTTP 请求的典型场景\n\n\n\n\n\nHypertext Transfer Protocol (HTTP) 协议\na stateless application-level request&#x2F;response protocol that usesextensible semantics and self-descriptive message payloads for flexibleinteraction with network-based hypertext information systems（RFC7230 2014.6）\n一种无状态的、应用层的、以请求&#x2F;应答方式运行的协议，它使用可扩展的语义和自描述消息格式，与基于网络的超文本信息系统灵活的互动\n\nHTTP 协议格式\n\n\n\nABNF （扩充巴科斯-瑙尔范式）操作符\n空白字符：用来分隔定义中的各个元素\nmethod SP request-target SP HTTP-version CRLF\n\n\n选择 &#x2F;：表示多个规则都是可供选择的规则\nstart-line &#x3D; request-line &#x2F; status-line\n\n\n值范围 %c##-## ：\nOCTAL &#x3D; “0” &#x2F; “1” &#x2F; “2” &#x2F; “3” &#x2F; “4” &#x2F; “5” &#x2F; “6” &#x2F; “7” 与 OCTAL &#x3D; %x30-37 等价\n\n\n序列组合 ()：将规则组合起来，视为单个元素\n不定量重复 m*n：\n元素表示零个或更多元素： *( header-field CRLF )\n1* 元素表示一个或更多元素，2*4 元素表示两个至四个元素\n\n\n可选序列 []：\n[ message-body ]\n\n\n\n核心规则\n\n基于 ABNF 描述的 HTTP 协议格式HTTP-message &#x3D; start-line *( header-field CRLF ) CRLF [ message-body ]\n\nstart-line &#x3D; request-line &#x2F; status-line\nrequest-line &#x3D; method SP request-target SP HTTP-version CRLF\nstatus-line &#x3D; HTTP-version SP status-code SP reason-phrase CRLF\n\n\nheader-field &#x3D; field-name “:” OWS field-value OWS\nOWS &#x3D; *( SP &#x2F; HTAB )\nfield-name &#x3D; token\nfield-value &#x3D; *( field-content &#x2F; obs-fold )\n\n\nmessage-body &#x3D; *OCTET\n\nOSI（Open System Interconnection Reference Model）概念模型\n\n\n\nOSI 模型与 TCP&#x2F;IP 模型对照\n\n\n\nWireshark 抓包及分析工具报文头部\n\nRoy Thomas Fielding 与 HTTP&#x2F;1.1\n参与制订 HTTP&#x2F;1.0 规范（1996.5）\n\n参与制订 URI 规范（1998.8）\n\n主导制订 HTTP&#x2F;1.1 规范（1999.6）\n\n2000 年发布指导 HTTP&#x2F;1.1 规范制订的论文\n\n《Architectural Style and the Design of Network-based SoftwareArchitectures》，即我们常谈的Representational State Transfer (REST)架构\n\n\nApache基金会（The Apache Software Foundation）共同创始人\n\n参与开发Apache httpd服务\n\n\n\nForm Follows Function：HTTP 协议为什么是现在这个样子\nHTTP 协议\n\nRoy Thomas Fielding：HTTP 主要作者，REST 架构作者\n\n\nURI：统一资源标识符\n\n\nHTTP 解决了什么问题？解决 WWW 信息交互必须面对的需求：• 低门槛• 可扩展性：巨大的用户群体，超长的寿命• 分布式系统下的 Hypermedia：大粒度数据的网络传输• Internet 规模• 无法控制的 scalability• 不可预测的负载、非法格式的数据、恶意消息• 客户端不能保持所有服务器信息，服务器不能保持多个请求间的状态信息• 独立的组件部署：新老组件并存• 向前兼容：自 1993 年起 HTTP0.9\\1.0（1996）已经被广泛使用\n评估 Web 架构的关键属性HTTP 协议应当在以下属性中取得可接受的均衡：\n性能 Performance：影响高可用的关键因素\n\n可伸缩性 Scalability：支持部署可以互相交互的大量组件\n\n简单性 Simplicity：易理解、易实现、易验证\n\n可见性 Visiable：对两个组件间的交互进行监视或者仲裁的能力。如缓存、分层设计等\n\n可移植性 Portability：在不同的环境下运行的能力\n\n可靠性 Reliability：出现部分故障时，对整体影响的程度\n\n可修改性 Modifiability：对系统作出修改的难易程度，由可进化性、可定制性、可扩展性、可配置性、可重用性构成\n\n\n架构属性：性能\n网络性能 Network Performance\nThroughput 吞吐量：小于等于带宽 bandwidth\nOverhead 开销：首次开销，每次开销\n\n\n用户感知到的性能 User-perceived Performance\nLatency 延迟：发起请求到接收到响应的时间\nCompletion 完成时间：完成一个应用动作所花费的时间\n\n\n网络效率 Network Efficiency\n重用缓存、减少交互次数、数据传输距离更近、COD\n\n\n\n架构属性：可修改性• 可进化性 Evolvability：一个组件独立升级而不影响其他组件• 可扩展性 Extensibility ：向系统添加功能，而不会影响到系统的其他部分• 可定制性 Customizability ：临时性、定制性地更改某一要素来提供服务，不对常规客户产生影响• 可配置性 Configurability ：应用部署后可通过修改配置提供新的功能• 可重用性 Reusabilit ：组件可以不做修改在其他应用在使用\n5 种架构风格\n数据流风格 Data-flow Styles\n优点：简单性、可进化性、可扩展性、可配置性、可重用性\n\n\n复制风格 Replication Styles\n优点：用户可察觉的性能、可伸缩性，网络效率、可靠性也可以提到提升\n\n\n分层风格 Hierarchical Styles\n优点：简单性、可进化性、可伸缩性\n\n\n移动代码风格 Mobile Code Styles\n优点：可移植性、可扩展性、网络效率\n\n\n点对点风格 Peer-to-Peer Styles\n优点：可进化性、可重用性、可扩展性、可配置性\n\n\n\nChrome 抓包：快速定位 HTTP 协议问题chrome-devtools\nChrome 抓包：Network 面板\n\n\n控制器：控制面板的外观与功能\n过滤器：过滤请求列表中显示的资源\n按住 Command （Mac）或 Ctrl （Window &#x2F; Linux），然后点击过滤器可以同时选择多个过滤器\n\n\n概览：显示 HTTP 请求、响应的时间轴\n请求列表：默认时间排序，可选择显示列\n概要：请求总数、总数据量、总花费时间等\n\n控制器\n\n过滤器：按类型\nXHR、JS、CSS、Img、Media、Font、Doc、WS (WebSocket)、Manifest 或 Other（此处未列出的任何其他类型）\n多类型，按住 Command (Mac) 或 Ctrl（Windows、Linux）\n按时间过滤：概览面板，拖动滚动条\n隐藏 Data URLs：CSS 图片等小文件以 BASE64 格式嵌入 HTML 中，以减少 HTTP请求数\n\n过滤器：属性过滤\ndomain：仅显示来自指定域的资源。 您可以使用通配符字符 (*) 纳入多个域\n\nhas-response-header：显示包含指定 HTTP 响应标头的资源\n\nis：使用 is:running 可以查找 WebSocket 资源，is:from-cache 可查找缓存读出的资源\n\nlarger-than： 显示大于指定大小的资源（以字节为单位）。 将值设为 1000 等同于设置为1k\n\nmethod：显示通过指定 HTTP 方法类型检索的资源\n\nmime-type：显示指定 MIME 类型的资源\n\nmixed-content：显示所有混合内容资源 (mixed-content:all)，或者仅显示当前显示的资源(mixed-content:displayed)。\n\nscheme：显示通过未保护 HTTP (scheme:http) 或受保护 HTTPS (scheme:https) 检索的资源。\n\nset-cookie-domain：显示具有 Set-Cookie 标头并且 Domain 属性与指定值匹配的资源。\n\nset-cookie-name：显示具有 Set-Cookie 标头并且名称与指定值匹配的资源。\n\nset-cookie-value：显示具有 Set-Cookie 标头并且值与指定值匹配的资源。\n\nstatus-code：仅显示 HTTP 状态代码与指定代码匹配的资源。\n\n\n多属性间通过空格实现 AND 操作\n请求列表的排序\n时间排序，默认\n按列排序\n按活动时间排序\nStart Time：发出的第一个请求位于顶部\nResponse Time：开始下载的第一个请求位于顶部\nEnd Time：完成的第一个请求位于顶部\nTotal Duration：连接设置时间和请求&#x2F;响应时间最短的请求位于顶部\nLatency：等待最短响应时间的请求位于顶部\n\n\n\n请求列表\nName : 资源的名称\nStatus : HTTP 状态代码\nType : 请求的资源的 MIME 类型\nInitiator : 发起请求的对象或进程。它可能有以下几种值：\nParser （解析器） : Chrome的 HTML 解析器发起了请求\n鼠标悬停显示 JS 脚本\n\n\nRedirect （重定向） : HTTP 重定向启动了请求\nScript （脚本） : 脚本启动了请求\nOther （其他） : 一些其他进程或动作发起请求，例如用户点击链接跳转到页面或在地址栏中输入网址\n\n\nSize : 服务器返回的响应大小（包括头部和包体），可显示解压后大小\nTime : 总持续时间，从请求的开始到接收响应中的最后一个字节\nWaterfall：各请求相关活动的直观分析图\n\n\n\n\n\n预览请求内容\n查看头部\n\n查看 cookie\n\n预览响应正文：查看图像用\n\n查看响应正文\n\n时间详细分布\n\n导出数据为 HAR 格式\n\n查看未压缩的资源大小：Use Large Request Rows\n\n浏览器加载时间（概览、概要、请求列表）\n\nDOMContentLoaded 事件的颜色设置为蓝色，而 load 事件设置为红色\n\n\n将请求数据复制到剪贴版\n\nCopy Link Address: 将请求的网址复制到剪贴板\nCopy Response: 将响应包体复制到剪贴板\nCopy as cURL: 以 cURL 命令形式复制请求\nCopy All as cURL: 以一系列 cURL 命令形式复制所有请求\nCopy All as HAR: 以 HAR 数据形式复制所有请求\n\n\n查看请求上下游：按住 shift 键悬停请求上，绿色是上游，红色是下游\n\n\n浏览器加载时间\n触发流程：\n解析 HTML 结构\n加载外部脚本和样式表文件\n解析并执行脚本代码 &#x2F;&#x2F; 部分脚本会阻塞页面的加载\nDOM 树构建完成 &#x2F;&#x2F; DOMContentLoaded 事件\n加载图片等外部文件\n页面加载完毕 &#x2F;&#x2F; load 事件\n\n\n\n请求时间详细分布\nQueueing: 浏览器在以下情况下对请求排队\n存在更高优先级的请求\n此源已打开六个 TCP 连接，达到限值，仅适用于 HTTP&#x2F;1.0 和 HTTP&#x2F;1.1\n浏览器正在短暂分配磁盘缓存中的空间\n\n\nStalled: 请求可能会因 Queueing 中描述的任何原因而停止\nDNS Lookup: 浏览器正在解析请求的 IP 地址\nProxy Negotiation: 浏览器正在与代理服务器协商请求\nRequest sent: 正在发送请求\nServiceWorker Preparation: 浏览器正在启动 Service Worker\nRequest to ServiceWorker: 正在将请求发送到 Service Worker\nWaiting (TTFB): 浏览器正在等待响应的第一个字节。 TTFB 表示 Time To First Byte（至第一字节的时间）。 此时间包括 1 次往返延迟时间及服务器准备响应所用的时间\nContent Download: 浏览器正在接收响应\nReceiving Push: 浏览器正在通过 HTTP&#x2F;2 服务器推送接收此响应的数据\nReading Push: 浏览器正在读取之前收到的本地数据\n\nURI的基本格式以及与URL的区别","categories":["web","network"],"tags":["wireshark"]},{"title":"《理论+实战 构建完整JVM知识体系》study notes","url":"/%E3%80%8A%E7%90%86%E8%AE%BA-%E5%AE%9E%E6%88%98-%E6%9E%84%E5%BB%BA%E5%AE%8C%E6%95%B4JVM%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E3%80%8Bstudy-notes/","content":"认识JVM规范JVM概述\nJVM：Java Virtual Machine\n\n所谓虚拟机是指：通过软件模拟的，具有完整硬件系统功能的、运行在一个完全隔离环境中的计算机\n\nJVM是通过软件来模拟Java字节码的指令集，是Java程序的运行环境\n\n\n\n\n\n\nJVM主要功能\n通过ClassLoader寻找和加载class文件\n解释字节码成机器指令并执行，提供class文件运行环境\n进行运行期间的内存分配和垃圾回收\n提供与硬件交互的平台\n\n\n\n虚拟机是java平台无关的保障\n\n\n\nJVM规范JVM规范的作用\nJava虚拟机规范为不通的硬件平台提供了一种编译Java技术代码的规范\n该规范使Java软件独立于平台，因为编译是针对作为虚拟机的 ”一般机器“ 而做\n这个 ”一般机器“ ，可用软件模拟，并运行于各种现存的计算机系统，也可用硬件来实现\n\n\n\nJVM规范主要内容\ncpu(字节码指令集）\nclass文件格式\n数据类型和值\n运行时数据区\n栈帧\n特殊方法\n类库\n异常\n虚拟机的启动、加载、连接和初始化\n\n\n\nClass字节码","categories":["java","jvm"],"tags":["jvm"]},{"title":"《透视 HTTP 协议》study notes","url":"/%E3%80%8A%E9%80%8F%E8%A7%86-HTTP-%E5%8D%8F%E8%AE%AE%E3%80%8Bstudy-notes/","content":"开篇词 (1讲)开篇词｜To Be a HTTP Hero备注","categories":["network","http"],"tags":["http","network"]},{"title":"Redis","url":"/Redis/","content":"初识RedisSQL与NoSQL\n\n\n\n\n\nSQL（关系型数据库）\nNoSQL（非关系数据库）\n\n\n\n数据结构\n结构化\n非结构化\n\n\n数据关联\n关联的\n无关联的\n\n\n查询方式\nSQL查询\n非SQL\n\n\n事务特性\nACID\nBASE\n\n\n存储方式\n磁盘\n内存\n\n\n扩展性\n垂直\n水平\n\n\n使用场景\n（1）数据结构固定（2）相关业务对数据安全性、一致性有较高要求\n（1）数据结构不固定（2）对一致性、安全性要求不高（3）对性能要求\n\n\n\n\n\n数据结构\n\n\n\n\n\n\n数据关联\n\n\n\n\n\n\n\n\n\n\nSQL查询\n\n\n\n\n\nRedis简介\nRedis诞生于2009年全称是Remote Dictionary Server，远程词典服务器，是一个基于内存的键值型NoSQL数据库。\n\n\n\nRedis特征\n键值（key-value）型，value支持多种不同数据结构，功能丰富\n单线程，每个命令具备原子性\n低延迟，速度快（基于内存、IO多路复用、良好的编码）\n支持数据持久化\n支持主从集群、分片集群\n支持多语言客户端\n\n\n\n单机安装Redis# 安装依赖 （Redis是基于C语言编写的，因此首先需要安装Redis所需要的gcc依赖）yum install -y gcc tcl# 上传/下载 安装包并解压[root@localhost install]# cd /install/[root@localhost install]# wget https://download.redis.io/releases/redis-6.2.7.tar.gz[root@localhost install]# ll总用量 2448drwxr-xr-x.  9 1001  1001     186 6月  12 05:34 nginx-1.16.1drwxr-xr-x.  9 1169  1169    8192 6月  12 05:42 pcre-8.43-rw-r--r--.  1 root root  2487287 4月  27 21:39 redis-6.2.7.tar.gzdrwxr-xr-x.  2 root root       83 6月  12 05:13 tar-gzdrwxr-xr-x. 14  501 games    4096 6月  12 05:42 zlib-1.2.11[root@localhost install]# tar -zxvf redis-6.2.7.tar.gz[root@localhost install]# ll总用量 2452drwxr-xr-x.  9 1001  1001     186 6月  12 05:34 nginx-1.16.1drwxr-xr-x.  9 1169  1169    8192 6月  12 05:42 pcre-8.43drwxrwxr-x.  7 root root     4096 4月  27 21:31 redis-6.2.7-rw-r--r--.  1 root root  2487287 4月  27 21:39 redis-6.2.7.tar.gzdrwxr-xr-x.  2 root root       83 6月  12 05:13 tar-gzdrwxr-xr-x. 14  501 games    4096 6月  12 05:42 zlib-1.2.11[root@localhost install]# mv redis-6.2.7 /usr/local/[root@localhost install]# cd /usr/local/[root@localhost local]# ln -s redis-6.2.7/ redis[root@localhost local]# ll总用量 4drwxr-xr-x.  2 root root    6 4月  11 2018 bindrwxr-xr-x.  2 root root    6 4月  11 2018 etcdrwxr-xr-x.  2 root root    6 4月  11 2018 gamesdrwxr-xr-x.  2 root root    6 4月  11 2018 includedrwxr-xr-x.  2 root root    6 4月  11 2018 libdrwxr-xr-x.  2 root root    6 4月  11 2018 lib64drwxr-xr-x.  2 root root    6 4月  11 2018 libexecdrwxr-xr-x. 12 root root  162 6月  12 05:48 nginxlrwxrwxrwx.  1 root root   12 7月   2 04:16 redis -&gt; redis-6.2.7/drwxrwxr-x.  7 root root 4096 7月   2 04:16 redis-6.2.7drwxr-xr-x.  2 root root    6 4月  11 2018 sbindrwxr-xr-x.  5 root root   49 5月  16 02:44 sharedrwxr-xr-x.  2 root root    6 4月  11 2018 src# 进入redis目录，运行编译命令。如果没有出错，应该就安装成功了[root@localhost local]# cd redis[root@localhost redis]# make &amp;&amp; make install# 默认的安装路径是在 `/usr/local/bin`目录下：[root@localhost redis]# cd /usr/local/bin/[root@localhost bin]# ll总用量 18924-rwxr-xr-x. 1 root root 4830048 7月   2 04:21 redis-benchmarklrwxrwxrwx. 1 root root      12 7月   2 04:21 redis-check-aof -&gt; redis-serverlrwxrwxrwx. 1 root root      12 7月   2 04:21 redis-check-rdb -&gt; redis-server-rwxr-xr-x. 1 root root 5004160 7月   2 04:21 redis-clilrwxrwxrwx. 1 root root      12 7月   2 04:21 redis-sentinel -&gt; redis-server-rwxr-xr-x. 1 root root 9535904 7月   2 04:21 redis-server# 该目录以及默认配置到环境变量，因此可以在任意目录下运行这些命令。其中：redis-cli# 是redis提供的命令行客户端redis-server# 是redis的服务端启动脚本redis-sentinel# 是redis的哨兵启动脚本\n\n\n\nRedis启动默认启动（前台启动）\n这种启动属于前台启动，会阻塞整个会话窗口，窗口关闭或者按下CTRL + C则Redis停止。不推荐使用。\n\nredis-server\n\n\n\n指定配置启动\n如果要让Redis以后台方式启动，则必须修改Redis配置文件\n\n# 我们先将这个配置文件备份一份：cp redis.conf redis.conf.bck\n\n\n然后修改redis.conf文件中的一些配置\n\n# 允许访问的地址，默认是127.0.0.1，会导致只能在本地访问。修改为0.0.0.0则可以在任意IP访问，生产环境不要设置为0.0.0.0bind 0.0.0.0# 守护进程，修改为yes后即可后台运行daemonize yes # 密码，设置后访问Redis必须输入密码requirepass redis\n\n\n指定配置启动\n\n# 进入redis安装目录 [root@localhost redis]# cd /usr/local/redis[root@localhost redis]# redis-server redis.conf[root@localhost redis]#[root@localhost redis]# ps -ef |grep redisroot       6421   1956  0 04:24 pts/0    00:00:01 redis-server *:6379root       6494   6432  0 04:35 pts/1    00:00:00 grep --color=auto redis\n\n\n\n开机自启（把redis添加到系统服务）\n我们也可以通过配置来实现开机自启，首先，新建一个系统服务文件\n\nvim /etc/systemd/system/redis.service\n\n\n内容如下\n\n[Unit]Description=redis-serverAfter=network.target[Service]Type=forkingExecStart=/usr/local/bin/redis-server /usr/local/redis/redis.confPrivateTmp=true[Install]WantedBy=multi-user.target\n\n\n然后重载系统服务\n\nsystemctl daemon-reload\n\n\n现在，我们可以用下面这组命令来操作redis了\n\n# 启动systemctl start redis# 停止systemctl stop redis# 重启systemctl restart redis# 查看状态systemctl status redis\n\n\n执行下面的命令，可以让redis开机自启\n\nsystemctl enable redis\n\n\n\n\n\nRedis的其它常见配置# 监听的端口port 6379# 工作目录，默认是当前目录，也就是运行redis-server时的命令，日志、持久化等文件会保存在这个目录dir .# 数据库数量，设置为1，代表只使用1个库，默认有16个库，编号0~15databases 1# 设置redis能够使用的最大内存maxmemory 512mb# 日志文件，默认为空，不记录日志，可以指定日志文件名logfile &quot;redis.log&quot;\n\n\n\nRedis停止# 利用redis-cli来执行 shutdown 命令，即可停止 Redis 服务，# 因为之前配置了密码，因此需要通过 -u 来指定密码redis-cli -u redis shutdown\n\n\n\nRedis客户端Redis命令行客户端redis-cli [options] [commonds]\n\n其中常见的options有：\n\n-h 127.0.0.1：指定要连接的redis节点的IP地址，默认是127.0.0.1\n-p 6379：指定要连接的redis节点的端口，默认是6379\n-a 123321：指定redis的访问密码\n\n其中的commonds就是Redis的操作命令，例如：\n\nping：与redis服务端做心跳测试，服务端正常会返回pong\n\n不指定commond时，会进入redis-cli的交互控制台：\n\n\n\n\n图形化桌面客户端\nhttps://github.com/lework/RedisDesktopManager-Windows/releases\n\n\n\nRedis的Java客户端\n\n\n\nJedisJedis使用的基本步骤（1）引入依赖\n&lt;!--Redis依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;redis.clients&lt;/groupId&gt;    &lt;artifactId&gt;jedis&lt;/artifactId&gt;    &lt;version&gt;4.2.0&lt;/version&gt;&lt;/dependency&gt;\n\n（2）创建Jedis对象，建立连接\nprivate Jedis jedis;   @BeforeEach   void testJedis() &#123;       jedis = new Jedis(&quot;192.168.163.200&quot;,6379);       jedis.auth(&quot;redis&quot;);       jedis.select(0);   &#125;\n\n（3）使用Jedis，方法名与Redis命令一致\n@Testvoid testString() &#123;    // 插入数据，方法名称就是redis命令名称，非常简单    String result = jedis.set(&quot;name&quot;, &quot;张三&quot;);    System.out.println(&quot;result = &quot; + result);    // 获取数据    String name = jedis.get(&quot;name&quot;);    System.out.println(&quot;name = &quot; + name);&#125;\n\n\n（4）释放资源\n@Deprecated   void tearDown() &#123;       if (jedis != null) &#123;           jedis.close();       &#125;   &#125;\n\n\n\nJedis连接池\nJedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此推荐大家使用Jedis连接池代替Jedis的直连方式\n\npublic class JedisConnectionFactory &#123;    private static final JedisPool jedisPool;    static &#123;        JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();        // 最大连接        jedisPoolConfig.setMaxTotal(8);        // 最大空闲连接        jedisPoolConfig.setMaxIdle(8);         // 最小空闲连接        jedisPoolConfig.setMinIdle(0);        // 设置最长等待时间， ms        jedisPoolConfig.setMaxWaitMillis(200);        jedisPool = new JedisPool(jedisPoolConfig, &quot;localhost&quot;, 6379,                1000, &quot;123321&quot;);    &#125;    // 获取Jedis对象    public static Jedis getJedis()&#123;        return jedisPool.getResource();    &#125;&#125;\n\n\n\nSpringDataRedisSpringDataRedis简介\nSpringData是Spring中数据操作的模块，包含对各种数据库的集成，其中对Redis的集成模块就叫做SpringDataRedis，官网地址：https://spring.io/projects/spring-data-redis\n\n提供了对不同Redis客户端的整合（Lettuce和Jedis）\n提供了RedisTemplate统一API来操作Redis\n支持Redis的发布订阅模型\n支持Redis哨兵和Redis集群\n支持基于Lettuce的响应式编程\n支持基于JDK、JSON、字符串、Spring对象的数据序列化及反序列化\n支持基于Redis的JDKCollection实现\n\n\nSpringDataRedis中提供了RedisTemplate工具类，其中封装了各种对Redis的操作。并且将不同数据类型的操作API封装到了不同的类型中：\n\n\n\n\n\nAPI\n返回值类型\n说明\n\n\n\nredisTemplate.opsForValue()\nValueOperations\n操作String类型数据\n\n\nredisTemplate.opsForHash()\nHashOperations\n操作Hash类型数据\n\n\nredisTemplate.opsForList()\nListOperations\n操作List类型数据\n\n\nredisTemplate.opsForSet()\nSetOperations\n操作Set类型数据\n\n\nredisTemplate.opsForZSet()\nZSetOperations\n操作SortedSet类型数据\n\n\nredisTemplate\n\n通用的命令\n\n\n\n\nSpringDataRedis快速入门\nSpringBoot已经提供了对SpringDataRedis的支持，使用非常简单\n\n（1）引入spring-boot-starter-data-redis依赖\n&lt;!--Redis依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--连接池依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;    &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt;\n\n（2）在application.yml配置Redis信息\nspring:  redis:    host: 192.168.163.200    port: 6379    password: redis    lettuce:      pool:        max-active: 8 # 最大连接        max-idle: 8 # 最大空闲连接        min-idle: 0 # 最小空闲连接        max-wait: 100 # 连接等待时间\n（3）注入RedisTemplate\n@Autowiredprivate RedisTemplate redisTemplate;\n\n（4）编写测试\n@SpringBootTestpublic class RedisTest &#123;    @Autowired    private RedisTemplate redisTemplate;    @Test    void testString() &#123;         // 插入一条string类型数据        redisTemplate.opsForValue().set(&quot;name&quot;, &quot;李四&quot;);        // 读取一条string类型数据        Object name = redisTemplate.opsForValue().get(&quot;name&quot;);        System.out.println(&quot;name = &quot; + name);    &#125;&#125;\n\n\n\nRedis Serializer（Redis序列化）SpringDataRedis的序列化方式\nRedisTemplate可以接收任意Object作为值写入Redis，只不过写入前会把Object序列化为字节形式，默认是采用JDK序列化\n\n\n\n\n缺点：\n可读性差\n内存占用较大\n\n\n\n\n\n自定义RedisTemplate的序列化方式@Configurationpublic class RedisConfig &#123;    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123;        // 创建Template        RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();        // 设置连接工厂        redisTemplate.setConnectionFactory(redisConnectionFactory);        // 设置序列化工具        GenericJackson2JsonRedisSerializer jsonRedisSerializer =                new GenericJackson2JsonRedisSerializer();        // key和 hashKey采用 string序列化        redisTemplate.setKeySerializer(RedisSerializer.string());        redisTemplate.setHashKeySerializer(RedisSerializer.string());        // value和 hashValue采用 JSON序列化        redisTemplate.setValueSerializer(jsonRedisSerializer);        redisTemplate.setHashValueSerializer(jsonRedisSerializer);        return redisTemplate;    &#125;&#125;\n\n@SpringBootTestpublic class RedisTest2 &#123;    @Autowired    private RedisTemplate&lt;String, Object&gt; redisTemplate;    @Test    void testString() &#123;        // 插入一条string类型数据        redisTemplate.opsForValue().set(&quot;name&quot;, &quot;李四&quot;);        // 读取一条string类型数据        Object name = redisTemplate.opsForValue().get(&quot;name&quot;);        System.out.println(&quot;name = &quot; + name);    &#125;    @Test    void testSaveObject() &#123;        redisTemplate.opsForValue().set(&quot;user:100&quot;,new Person(&quot;果冻&quot;,28));        Person person = (Person) redisTemplate.opsForValue().get(&quot;user:100&quot;);        System.out.println(person);    &#125;\n\n\n\nStringRedisTemplate（RedisTemplate的序列化方式优化）\n尽管JSON的序列化方式可以满足我们的需求，但依然存在一些问题\n\n\n\n\n为了在反序列化时知道对象的类型，JSON序列化器会将类的class类型写入json结果中，存入Redis，会带来额外的内存开销\n\n为了节省内存空间，我们并不会使用JSON序列化器来处理value，而是统一使用String序列化器，要求只能存储String类型的key和value。当需要存储Java对象时，手动完成对象的序列化和反序列化\n\n\n\n\n\nSpring默认提供了一个StringRedisTemplate类，它的key和value的序列化方式默认就是String方式。省去了我们自定义RedisTemplate的过程：\n\n@SpringBootTestpublic class StingRedisTemplateTests &#123;    @Autowired    private StringRedisTemplate stringRedisTemplate;    // JSON工具    private static final ObjectMapper mapper = new ObjectMapper();    @Test    void testStringTemplate() throws JsonProcessingException &#123;        // 准备对象        Person user = new Person(&quot;lily&quot;, 18);        // 手动序列化        String json = mapper.writeValueAsString(user);        // 写入一条数据到redis        stringRedisTemplate.opsForValue().set(&quot;user:200&quot;, json);        // 读取数据        String val = stringRedisTemplate.opsForValue().get(&quot;user:200&quot;);        // 反序列化        Person user1 = mapper.readValue(val, Person.class);        System.out.println(&quot;user1 = &quot; + user1);    &#125;&#125;\n\n\n\nRedisTemplate序列化总结RedisTemplate的两种序列化实践方案：\n方案一：\n\n自定义RedisTemplate\n修改RedisTemplate的序列化器为GenericJackson2JsonRedisSerializer\n\n\n方案二：\n\n使用StringRedisTemplate\n写入Redis时，手动把对象序列化为JSON\n读取Redis时，手动把读取到的JSON反序列化为对象\n\n\n\n\n\nRedis企业实战商户点评\n\n\n\n目录\n短信登录\n商户查询缓存\n优惠券秒杀\n达人探店\n好友关注\n附近的商户\n用户签到\nUV统计\n\n\n\n短信登录（1）导入商户点评项目\n项目下载地址\n\n\nhm-dianping.zip (将其下载解压缩后复制到idea工作空间，然后利用idea打开即可)（修改自己的MySQL和Redis配置）\n\n启动项目后，在浏览器访问：http://localhost:8081/shop-type/list ，如果可以看到数据则证明运行没有问题\n\nhmdp.sql（导入SQL文件。Mysql的版本采用5.7及以上版本）（注意先创建数据库）\nnginx-1.18.0.zip（windows版本。解压缩后启动即可）\n\n访问: http://127.0.0.1:8080 ，即可看到页面\n\n\n\n\n\n\n\n\n（2）基于Session实现登录\n\n\n\n集群的session共享问题\n基于Redis实现共享session登录\n\n","categories":["database","redis"],"tags":["redis"]},{"title":"《Nginx体系化深度精讲》study notes","url":"/%E3%80%8ANginx%E4%BD%93%E7%B3%BB%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%B2%BE%E8%AE%B2%E3%80%8Bstudy-notes/","content":"Nginx初体验安装第一个rpm包Nginx# 下载epel yum源yum install epel-release -y# 查看yum源里可安装的nginxyum list all |grep nginx# 下载nginxyum install nginx -y# 列出 nginx 安装的文件rpm -ql nginx# 查看nginx启动文件所在目录rpm -ql nginx |grep bin/sur/sbin/nginx\n\n\n\nNginx进程结构与热部署Nginx的进程结构\n\n\n真正处理请求的不是 master process，二是 worker process\n\n\n\nLinux的信号量管理机制\nlinux中的所有信号量\n\n[root@localhost nginx]# kill -l 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR111) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+338) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+843) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-758) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-263) SIGRTMAX-1  64) SIGRTMAX\n\n\n常用信号量\n\n\n\n利用信号量管理Nginx# 关闭nginxkill -s SIGTERM [nginx master进程pid]# 重新读取配置文件，会关闭之前的work子进程，生成新的work子进程 kill -s SIGHUP [nginx master进程pid]\n\n\n\n\n\n\n配置文件重载的原理真相reload 重载配置文件的流程\n向master进程发送HUP信号（reload命令）\nmaster进程检查配置语法是否正确\nmaster进程打开监听端口\nmaster进程使用新的配置文件启动新的worker子进程\nmaster进程向老的worker子进程发送QUIT信号\n旧的worker进程关闭监听句柄，处理完当前连接后关闭进程\n\n\n\n\n\nNginx的热部署热升级的流程\n将旧的nginx文件替换成新的nginx文件\n向master进程发送USR2信号\nmaster进程修改pid文件，加后缀.oldbin\nmaster进程用新nginx文件启动新master进程\n向旧的master进程发送WINCH信号，旧的worker子进程退出\n回滚槽形：向旧master发送HUP ,向新的master发送QUIT\n\n\n\nNginx热部署完整步骤演示cp nginx nginx.bakkill -s SIGUSR2 19932kill -s SIGWINCH 19932kill -s SIGQUIT 19932# 让旧master进程 启动work子进程（使用的还是旧的nginx二进制文件）kill -s SIGHUP 20650\n\n\n注意事项\n\n\n不能使用 kill -s SIGHU [] 退出旧的master进程，如果这样做的话，旧的 master主进程和其子进程会直接退出（被kill掉），这样（当新启的nginx进程有问题时）就无法回滚。\n所以应该使用 kill -s SIGWINCH []，先将旧的master主进程下的work子进程全部kill掉，验证新启的nginx进程没有问题后，再使用 kill -s SIGHU []\tkill掉旧的master进程。如果验证新启的nginx进程有问题，这时使用 kill -s SIGHUP [] 就可以让旧master进程重新启动work子进程。（达到回滚的效果）\n\n正常升级[root@localhost nginx]# /opt/nginx/nginx[root@localhost nginx]# ps -ef |grep nginxroot      19932      1  0 07:28 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     19933  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19934  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19935  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19936  19932  0 07:28 ?        00:00:00 nginx: worker processroot      19938  10122  0 07:28 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]#[root@localhost nginx]# cd /opt/nginx/[root@localhost nginx]# ll总用量 1240-rwxr-xr-x. 1 root root 1266632 10月 19 2021 nginx[root@localhost nginx]# cp nginx nginx.bak[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      19932      1  0 07:28 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     19933  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19934  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19935  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19936  19932  0 07:28 ?        00:00:00 nginx: worker processroot      19942  10122  0 07:30 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]# ll总用量 2480-rwxr-xr-x. 1 root root 1266632 10月 19 2021 nginx-rwxr-xr-x. 1 root root 1266632 5月  16 07:30 nginx.bak[root@localhost nginx]#[root@localhost nginx]# kill -s SIGUSR2 19932[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      19932      1  0 07:28 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     19933  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19934  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19935  19932  0 07:28 ?        00:00:00 nginx: worker processnginx     19936  19932  0 07:28 ?        00:00:00 nginx: worker processroot      19944  19932  0 07:31 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     19945  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19946  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19947  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19948  19944  0 07:31 ?        00:00:00 nginx: worker processroot      19950  10122  0 07:32 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]#[root@localhost nginx]#[root@localhost nginx]# ll /run/总用量 32-rw-r--r--.  1 root root    4 5月  16 02:49 auditd.piddrwxr-xr-x.  2 root root   80 5月  16 02:49 blkiddrwxr-xr-x.  2 root root   40 5月  16 02:49 console-rw-r--r--.  1 root root    4 5月  16 02:49 crond.pid----------.  1 root root    0 5月  16 02:49 cron.rebootdrwx------.  2 root root   40 5月  16 02:49 cryptsetupdrwxr-xr-x.  2 root root   60 5月  16 02:49 dbusprw-------.  1 root root    0 5月  16 02:49 dmeventd-clientprw-------.  1 root root    0 5月  16 02:49 dmeventd-server-rw-------.  1 root root    0 5月  16 02:49 ebtables.lockdrwxr-xr-x.  2 root root   40 5月  16 02:49 faillockdrwxr-x---.  2 root root   40 5月  16 03:52 firewallddrwxr-xr-x.  4 root root  120 5月  16 02:49 initramfsdrwxr-xr-x.  5 root root  120 5月  16 03:48 lockdrwxr-xr-x.  3 root root   60 5月  16 02:49 logdrwx------.  3 root root  100 5月  16 02:49 lvm-rw-r--r--.  1 root root    4 5月  16 02:49 lvmetad.piddrwxr-xr-x.  2 root root   40 5月  16 02:49 mountdrwxrwxr-x.  2 root root   40 5月  16 02:49 netreportdrwxr-xr-x.  3 root root  120 5月  16 02:59 NetworkManager-rw-r--r--.  1 root root    6 5月  16 07:31 nginx.pid-rw-r--r--.  1 root root    6 5月  16 07:28 nginx.pid.oldbindrwxr-xr-x.  2 root root   40 5月  16 02:49 plymouthdrwxr-xr-x.  2 root root   40 5月  16 02:49 sepermitdrwxr-xr-x.  2 root root   40 5月  16 02:49 setrans-rw-r--r--.  1 root root    5 5月  16 02:49 sshd.piddrwx--x--x.  3 root root   60 5月  16 02:49 sudo-rw-------.  1 root root    4 5月  16 02:49 syslogd.piddrwxr-xr-x. 19 root root  460 5月  16 03:38 systemddrwxr-xr-x.  2 root root   60 5月  16 02:49 tmpfiles.ddrwxr-xr-x.  2 root root   60 5月  16 02:49 tuneddrwxr-xr-x.  7 root root  160 5月  16 07:33 udevdrwxr-xr-x.  3 root root   60 5月  16 02:49 user-rw-rw-r--.  1 root utmp 2304 5月  16 07:32 utmp-rw-------.  1 root root    0 5月  16 02:49 xtables.lock[root@localhost nginx]#[root@localhost nginx]# cat /run/nginx.pid.oldbin19932[root@localhost nginx]# cat /run/nginx.pid19944[root@localhost nginx]# kill -s SIGWINCH 19932[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      19932      1  0 07:28 ?        00:00:00 nginx: master process /opt/nginx/nginxroot      19944  19932  0 07:31 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     19945  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19946  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19947  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19948  19944  0 07:31 ?        00:00:00 nginx: worker processroot      20115  10122  0 07:36 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]#[root@localhost nginx]#[root@localhost nginx]# kill -s SIGQUIT 19932[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      19944      1  0 07:31 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     19945  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19946  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19947  19944  0 07:31 ?        00:00:00 nginx: worker processnginx     19948  19944  0 07:31 ?        00:00:00 nginx: worker processroot      20181  10122  0 07:37 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]# ll /run/总用量 28-rw-r--r--.  1 root root    4 5月  16 02:49 auditd.piddrwxr-xr-x.  2 root root   80 5月  16 02:49 blkiddrwxr-xr-x.  2 root root   40 5月  16 02:49 console-rw-r--r--.  1 root root    4 5月  16 02:49 crond.pid----------.  1 root root    0 5月  16 02:49 cron.rebootdrwx------.  2 root root   40 5月  16 02:49 cryptsetupdrwxr-xr-x.  2 root root   60 5月  16 02:49 dbusprw-------.  1 root root    0 5月  16 02:49 dmeventd-clientprw-------.  1 root root    0 5月  16 02:49 dmeventd-server-rw-------.  1 root root    0 5月  16 02:49 ebtables.lockdrwxr-xr-x.  2 root root   40 5月  16 02:49 faillockdrwxr-x---.  2 root root   40 5月  16 03:52 firewallddrwxr-xr-x.  4 root root  120 5月  16 02:49 initramfsdrwxr-xr-x.  5 root root  120 5月  16 03:48 lockdrwxr-xr-x.  3 root root   60 5月  16 02:49 logdrwx------.  3 root root  100 5月  16 02:49 lvm-rw-r--r--.  1 root root    4 5月  16 02:49 lvmetad.piddrwxr-xr-x.  2 root root   40 5月  16 02:49 mountdrwxrwxr-x.  2 root root   40 5月  16 02:49 netreportdrwxr-xr-x.  3 root root  120 5月  16 02:59 NetworkManager-rw-r--r--.  1 root root    6 5月  16 07:31 nginx.piddrwxr-xr-x.  2 root root   40 5月  16 02:49 plymouthdrwxr-xr-x.  2 root root   40 5月  16 02:49 sepermitdrwxr-xr-x.  2 root root   40 5月  16 02:49 setrans-rw-r--r--.  1 root root    5 5月  16 02:49 sshd.piddrwx--x--x.  3 root root   60 5月  16 02:49 sudo-rw-------.  1 root root    4 5月  16 02:49 syslogd.piddrwxr-xr-x. 19 root root  460 5月  16 03:38 systemddrwxr-xr-x.  2 root root   60 5月  16 02:49 tmpfiles.ddrwxr-xr-x.  2 root root   60 5月  16 02:49 tuneddrwxr-xr-x.  7 root root  160 5月  16 07:33 udevdrwxr-xr-x.  3 root root   60 5月  16 02:49 user-rw-rw-r--.  1 root utmp 2304 5月  16 07:32 utmp-rw-------.  1 root root    0 5月  16 02:49 xtables.lock[root@localhost nginx]#[root@localhost nginx]# ll总用量 2480-rwxr-xr-x. 1 root root 1266632 10月 19 2021 nginx-rwxr-xr-x. 1 root root 1266632 5月  16 07:30 nginx.bak[root@localhost nginx]# rm -rf nginx.bak[root@localhost nginx]# ll总用量 1240-rwxr-xr-x. 1 root root 1266632 10月 19 2021 nginx[root@localhost nginx]#\n\n\n\n回滚情形[root@localhost nginx]# /opt/nginx/nginx[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      20650      1  0 07:46 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     20651  20650  0 07:46 ?        00:00:00 nginx: worker processnginx     20652  20650  0 07:46 ?        00:00:00 nginx: worker processnginx     20653  20650  0 07:46 ?        00:00:00 nginx: worker processnginx     20654  20650  0 07:46 ?        00:00:00 nginx: worker processroot      20670  10122  0 07:46 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]# cd /opt/nginx/[root@localhost nginx]# ll总用量 1240-rwxr-xr-x. 1 root root 1266632 5月  16 07:44 nginx[root@localhost nginx]# cp nginx nginx.bak[root@localhost nginx]#[root@localhost nginx]# kill -s SIGUSR2 20650[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      20650      1  0 07:46 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     20651  20650  0 07:46 ?        00:00:00 nginx: worker processnginx     20652  20650  0 07:46 ?        00:00:00 nginx: worker processnginx     20653  20650  0 07:46 ?        00:00:00 nginx: worker processnginx     20654  20650  0 07:46 ?        00:00:00 nginx: worker processroot      20698  20650  0 07:47 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     20699  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20700  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20701  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20702  20698  0 07:47 ?        00:00:00 nginx: worker processroot      20711  10122  0 07:47 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]# ll总用量 2480-rwxr-xr-x. 1 root root 1266632 5月  16 07:44 nginx-rwxr-xr-x. 1 root root 1266632 5月  16 07:46 nginx.bak[root@localhost nginx]# ll /run/总用量 32-rw-r--r--.  1 root root    4 5月  16 02:49 auditd.piddrwxr-xr-x.  2 root root   80 5月  16 02:49 blkiddrwxr-xr-x.  2 root root   40 5月  16 02:49 console-rw-r--r--.  1 root root    4 5月  16 02:49 crond.pid----------.  1 root root    0 5月  16 02:49 cron.rebootdrwx------.  2 root root   40 5月  16 02:49 cryptsetupdrwxr-xr-x.  2 root root   60 5月  16 02:49 dbusprw-------.  1 root root    0 5月  16 02:49 dmeventd-clientprw-------.  1 root root    0 5月  16 02:49 dmeventd-server-rw-------.  1 root root    0 5月  16 02:49 ebtables.lockdrwxr-xr-x.  2 root root   40 5月  16 02:49 faillockdrwxr-x---.  2 root root   40 5月  16 03:52 firewallddrwxr-xr-x.  4 root root  120 5月  16 02:49 initramfsdrwxr-xr-x.  5 root root  120 5月  16 03:48 lockdrwxr-xr-x.  3 root root   60 5月  16 02:49 logdrwx------.  3 root root  100 5月  16 02:49 lvm-rw-r--r--.  1 root root    4 5月  16 02:49 lvmetad.piddrwxr-xr-x.  2 root root   40 5月  16 02:49 mountdrwxrwxr-x.  2 root root   40 5月  16 02:49 netreportdrwxr-xr-x.  3 root root  120 5月  16 02:59 NetworkManager-rw-r--r--.  1 root root    6 5月  16 07:47 nginx.pid-rw-r--r--.  1 root root    6 5月  16 07:46 nginx.pid.oldbindrwxr-xr-x.  2 root root   40 5月  16 02:49 plymouthdrwxr-xr-x.  2 root root   40 5月  16 02:49 sepermitdrwxr-xr-x.  2 root root   40 5月  16 02:49 setrans-rw-r--r--.  1 root root    5 5月  16 02:49 sshd.piddrwx--x--x.  3 root root   60 5月  16 02:49 sudo-rw-------.  1 root root    4 5月  16 02:49 syslogd.piddrwxr-xr-x. 19 root root  460 5月  16 03:38 systemddrwxr-xr-x.  2 root root   60 5月  16 02:49 tmpfiles.ddrwxr-xr-x.  2 root root   60 5月  16 02:49 tuneddrwxr-xr-x.  7 root root  160 5月  16 07:33 udevdrwxr-xr-x.  3 root root   60 5月  16 02:49 user-rw-rw-r--.  1 root utmp 2304 5月  16 07:32 utmp-rw-------.  1 root root    0 5月  16 02:49 xtables.lock[root@localhost nginx]#[root@localhost nginx]#[root@localhost nginx]# kill -s SIGWINCH 20650[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      20650      1  0 07:46 ?        00:00:00 nginx: master process /opt/nginx/nginxroot      20698  20650  0 07:47 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     20699  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20700  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20701  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20702  20698  0 07:47 ?        00:00:00 nginx: worker processroot      20780  10122  0 07:48 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]#[root@localhost nginx]# kill -s SIGHUP 20650[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      20650      1  0 07:46 ?        00:00:00 nginx: master process /opt/nginx/nginxroot      20698  20650  0 07:47 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     20699  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20700  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20701  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20702  20698  0 07:47 ?        00:00:00 nginx: worker processnginx     20815  20650  0 07:49 ?        00:00:00 nginx: worker processnginx     20816  20650  0 07:49 ?        00:00:00 nginx: worker processnginx     20817  20650  0 07:49 ?        00:00:00 nginx: worker processnginx     20818  20650  0 07:49 ?        00:00:00 nginx: worker processroot      20825  10122  0 07:49 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]#[root@localhost nginx]#[root@localhost nginx]# kill -s SIGQUIT 20698[root@localhost nginx]#[root@localhost nginx]# ps -ef |grep nginxroot      20650      1  0 07:46 ?        00:00:00 nginx: master process /opt/nginx/nginxnginx     20815  20650  0 07:49 ?        00:00:00 nginx: worker processnginx     20816  20650  0 07:49 ?        00:00:00 nginx: worker processnginx     20817  20650  0 07:49 ?        00:00:00 nginx: worker processnginx     20818  20650  0 07:49 ?        00:00:00 nginx: worker processroot      20935  10122  0 07:51 pts/2    00:00:00 grep --color=auto nginx[root@localhost nginx]#[root@localhost nginx]# cat /run/nginx.pid20650[root@localhost nginx]# ll /run/总用量 28-rw-r--r--.  1 root root    4 5月  16 02:49 auditd.piddrwxr-xr-x.  2 root root   80 5月  16 02:49 blkiddrwxr-xr-x.  2 root root   40 5月  16 02:49 console-rw-r--r--.  1 root root    4 5月  16 02:49 crond.pid----------.  1 root root    0 5月  16 02:49 cron.rebootdrwx------.  2 root root   40 5月  16 02:49 cryptsetupdrwxr-xr-x.  2 root root   60 5月  16 02:49 dbusprw-------.  1 root root    0 5月  16 02:49 dmeventd-clientprw-------.  1 root root    0 5月  16 02:49 dmeventd-server-rw-------.  1 root root    0 5月  16 02:49 ebtables.lockdrwxr-xr-x.  2 root root   40 5月  16 02:49 faillockdrwxr-x---.  2 root root   40 5月  16 03:52 firewallddrwxr-xr-x.  4 root root  120 5月  16 02:49 initramfsdrwxr-xr-x.  5 root root  120 5月  16 03:48 lockdrwxr-xr-x.  3 root root   60 5月  16 02:49 logdrwx------.  3 root root  100 5月  16 02:49 lvm-rw-r--r--.  1 root root    4 5月  16 02:49 lvmetad.piddrwxr-xr-x.  2 root root   40 5月  16 02:49 mountdrwxrwxr-x.  2 root root   40 5月  16 02:49 netreportdrwxr-xr-x.  3 root root  120 5月  16 02:59 NetworkManager-rw-r--r--.  1 root root    6 5月  16 07:46 nginx.piddrwxr-xr-x.  2 root root   40 5月  16 02:49 plymouthdrwxr-xr-x.  2 root root   40 5月  16 02:49 sepermitdrwxr-xr-x.  2 root root   40 5月  16 02:49 setrans-rw-r--r--.  1 root root    5 5月  16 02:49 sshd.piddrwx--x--x.  3 root root   60 5月  16 02:49 sudo-rw-------.  1 root root    4 5月  16 02:49 syslogd.piddrwxr-xr-x. 19 root root  460 5月  16 03:38 systemddrwxr-xr-x.  2 root root   60 5月  16 02:49 tmpfiles.ddrwxr-xr-x.  2 root root   60 5月  16 02:49 tuneddrwxr-xr-x.  7 root root  160 5月  16 07:33 udevdrwxr-xr-x.  3 root root   60 5月  16 02:49 user-rw-rw-r--.  1 root utmp 2304 5月  16 07:32 utmp-rw-------.  1 root root    0 5月  16 02:49 xtables.lock[root@localhost nginx]# ll总用量 2480-rwxr-xr-x. 1 root root 1266632 5月  16 07:44 nginx-rwxr-xr-x. 1 root root 1266632 5月  16 07:46 nginx.bak[root@localhost nginx]# rm -rf nginx[root@localhost nginx]# mv nginx.bak nginx[root@localhost nginx]# ll总用量 1240-rwxr-xr-x. 1 root root 1266632 5月  16 07:46 nginx[root@localhost nginx]#\n\nNginx模块化设计机制模块结构图\n\n\n\n模块体系结构\n\n\n\nNginx编译安装的配置参数\n\n定制编译安装Nginx# 准备安装文件[root@localhost tar-gz]# ll总用量 3648-rw-r--r--. 1 root root 1032630 8月  14 2019 nginx-1.16.1.tar.gz-rw-r--r--. 1 root root 2085854 6月  12 05:09 pcre-8.43.tar.gz-rw-r--r--. 1 root root  607698 1月  16 2017 zlib-1.2.11.tar.gz# 全部解压[root@localhost install]# lldrwxr-xr-x.  8 1001  1001  158 8月  13 2019 nginx-1.16.1drwxr-xr-x.  7 1169  1169 8192 2月  24 2019 pcre-8.43drwxr-xr-x. 14  501 games 4096 1月  16 2017 zlib-1.2.11# 解压后进入 nginx源码目录，查看相关编译参数[root@localhost nginx-1.16.1]# ./configure --help# 编译安装前下载相关依赖[root@localhost nginx-1.16.1]# yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel gd gd-devel[root@localhost nginx-1.16.1]# ./configure --prefix=/usr/local/nginx --conf-path=/usr/local/nginx/conf/nginx.conf --user=nginx --group=nginx --pid-path=/usr/local/nginx/pid/nginx.pid --error-log-path=/usr/local/nginx/logs/error.log --with-pcre=/install/pcre-8.43 --with-zlib=/install/zlib-1.2.11 --with-http_ssl_module --with-http_image_filter_module --with-http_stub_status_module --http-log-path=/usr/local/nginx/logs/access.log[root@localhost nginx-1.16.1]# make[root@localhost nginx-1.16.1]# make install[root@localhost nginx-1.16.1]# cd /usr/local/nginx/[root@localhost nginx]# ll总用量 4drwxr-xr-x. 2 root root 4096 6月  12 05:43 confdrwxr-xr-x. 2 root root   40 6月  12 05:43 htmldrwxr-xr-x. 2 root root    6 6月  12 05:43 logsdrwxr-xr-x. 2 root root    6 6月  12 05:43 piddrwxr-xr-x. 2 root root   19 6月  12 05:43 sbin[root@localhost sbin]# useradd nginx[root@localhost nginx]# pwd/usr/local/nginx[root@localhost nginx]#[root@localhost nginx]# sbin/nginx[root@localhost nginx]# ps -ef | grep nginxroot      12464      1  0 05:48 ?        00:00:00 nginx: master process sbin/nginxnginx     12465  12464  0 05:48 ?        00:00:00 nginx: worker processroot      12473   1840  0 05:48 pts/1    00:00:00 \n\nNginx配置文件结构\n\n虚拟主机的分类（三种）\n基于多IP的虚拟主机\n基于多端口的虚拟主机\n基于域名的虚拟主机\n\n核心指令-Nginx基础应用配置文件main段核心参数用法# main段核心参数:user USERNAME [GROUP]    解释：指定运行nginx的worker子进程的属主和属组，其中属组可以不指定 \t示例：\t\tuser nginx nginx;pid DIR    解释：指定运行nginx的mas ter主进程的pid文件存放路径 \t示例：\t\tpid /ropt/nginx/logs/nginx.pid;worker_rlimit_nofile number   \t解春：指定worker子进程可以打开的最大文件句柄数 \t示例：         worker_rlimit_nofile 20480;worker_rlimit_core size \t一 解释：指定worker子进程异常终止后的core文件，用于记录分析问题 \t示例：         worker_rlimit_core 50M；         working_directory /opt/nginx/tmp;worker_processes number | auto   解释：指定nginx启动的worker子进程数量   示例：         worker_processes 4;         worker_processes auto;worker_cpu_affinity cpumaskl cpumask2...   解霹：将每个worker子进程与我们的CPU物理核心绑定。   示例：         worker_cpu_affinity 0001 0010 0100 1000； #         4个物理核心，4个worker子进程         worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000         00100060 01000000 10000000; # 8物理核心，8个worker子进程         worker_cpu_affinity 01 10 01 10;         # 2个物理核心，4个子进程  备注：将每个worker子进程与特定CPU物理核心绑定，优势在于：避免同个worker子进程  在不同的CPU核心上切换，缓存失效，降低性能；其并不能真正的避免进程切换worker_priority number   解释：指定worker子进程的nice值，以调整运行nginx的优先级，通常设定为负值，以优先 调用nginx   示例：        worker_priority -10;   备注：Linux默认进程的优先级值是120,值越小越优先；nice设定范围为-20到+19worker_shutdown_timeout time   解春：指定证rker子进程优雅退出时的超时时间   示例：        worker_shutdown_timeout 5s;timer_resolution time   解释：worker子进程内部使用的计时器精度，调整时间间隔越大，系统调用越少，有利于性 能提升；反之，系统调用越多，性能下降   示例：        worker_resolution 100ms;daemon on|off  解释：设定nginx的运行方式，前台还是后台，前台用户调试，后台用于生产 示例：       daemon off;\n\n配置文件events段核心参数用法\n\n\n参数\n含义\n\n\n\nuse\nnginx使用何种事件驱动模型\n\n\nworker_connections\nworker子进程能够处理的最大并发连接数\n\n\naccept_mutex\n是否打开负载均衡互斥锁\n\n\naccept_mutex_delay\n新连接分配给worker子进程的超时时间\n\n\nlock_file\n负载均衡互斥锁文件存放路径\n\n\nmuti_accept\nworker子进程可以接收的新连接个数\n\n\n备注\nlinux信号量这块的管理机制可以再抽时间深入理解一下\n\n","categories":["nginx"],"tags":["nginx"]}]